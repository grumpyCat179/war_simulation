WarSim Pro âš”ï¸

Production-Grade 2-D Multi-Agent Battle Simulator
Branch: main

Overview

WarSim Pro is a research-grade rewrite of a 2-D multi-agent combat simulator, built with a focus on determinism, modularity, and high performance.

The pipeline is cleanly decomposed into:
perception â†’ ego-frame â†’ policy â†’ mask â†’ sampling â†’ engine â†’ grid

Explicit ABI contracts define actions, directions, observations, and masks. Performance-critical paths are vectorised and GPU-friendly, enabling thousands of agents to run at â‰¥60 ticks/second on a 128Ã—128 grid ğŸš€.

Design Tenets ğŸ§©

Contracts over code â€“ All directional/action layouts follow rigid schemas, simplifying rotation and masking.

Strict modularity â€“ Each layer is independently swappable; seam tests pin down invariants.

Performance discipline â€“ Struct-of-Arrays (SoA) tensors and batched inference minimise Python overhead.

Observability & testability â€“ Built-in stats, logs, and property tests catch regressions early.

Determinism knobs â€“ Seeds and fixed initialisation guarantee reproducibility.

System Architecture ğŸ“Š

The runtime consists of:

Tick Engine â€“ Updates health, movement, collisions, and scoring.

Agents Registry â€“ Manages SoA data and brain assignments.

Ego-Frame Runtime â€“ Rotates observations into an ego-centric frame, then unrotates logits.

Bucketer â€“ Groups agents by brain topology for efficient batched inference.

Mask Builder â€“ Enforces legal action constraints.

Sampler â€“ Draws final actions from masked logits.

All components interlock under a deterministic, test-driven runtime.

Repository Layout
war_simulation/
â”œâ”€â”€ agent/       # Agent brains (actor-critic, encoders)
â”œâ”€â”€ engine/      # Core engine: ticks, grid, raycasting, mapgen
â”œâ”€â”€ rl/          # PPO and other RL algorithms
â”œâ”€â”€ scripts/     # Training & launch scripts
â”œâ”€â”€ tests/       # Unit & property tests pinning ABI contracts
â”œâ”€â”€ config.py    # Centralised knobs & hyper-parameters

Installation & Quick Start
Prerequisites

Windows 11

Python 3.10

CUDA 12.x

PyTorch â‰¥ 2.1

GPU: RTX 3060 (6 GB VRAM recommended)

Setup
git clone https://github.com/grumpyCat179/war_simulation.git
cd war_simulation
python -m venv .venv && source .venv/bin/activate  # optional
pip install -r requirements.txt
pip install -e .

Run a Headless Simulation
python -m war_simulation.main --ticks 2000 --grid 128 128 --agents 1000


Per-tick stats are logged to console or file.

Configuration

All runtime knobs live in config.py (or via FWS_* environment variables).
Key options include:

GRID_WIDTH, GRID_HEIGHT â€“ world size (default 128Ã—128)

NUM_ACTIONS â€“ 17 (melee) or 41 (ranged)

RAY_PE_DIM, RAY_ATTN_DIM â€“ ray encoder capacity

MAX_AGENTS â€“ maximum allocated agents

RESPAWN_COOLDOWN_TICKS, RESPAWN_BATCH_PER_TEAM â€“ respawn controls

âš ï¸ Avoid modifying config dynamically inside hot loops.

Agent Brain

Default per-agent brain = tiny actor-critic:

RayEncoder â€“ projects 64 ray features into 32-D context, with optional ring positional encoding and light self-attention.

MLP Trunk â€“ three SiLU layers.

Output Heads â€“ actor (logits over actions) + critic (value).

Directional Factorisation â€“ actions grouped into 8-wide move/melee/ranged heads for clarity.

This balances throughput with directional context capture.

Tick Loop

Each tick performs:

Observation â€“ raycast & gather environment features.

Ego Rotation â€“ align rays with agent heading.

Bucketing â€“ group by brain topology.

Policy Forward â€“ actor-critic inference, logits unrotated.

Mask & Sampling â€“ legal mask applied, actions sampled.

Engine Update â€“ apply movement, combat, scoring.

(Optional) Mutation â€“ inject small parameter noise or structural variation.

Performance & Testing

Optimisation tips in the Performance Playbook (e.g. set RAY_ATTN_DIM=0 to disable attention).

Batch sizes â‰¥64 recommended.

Tests under tests/ enforce invariants:

pytest -q

Branch Notes

This main branch is the baseline WarSim Pro:

Emphasises clarity, modularity, and performance.

Other branches may contain experimental features or trained policies; see their respective READMEs.
